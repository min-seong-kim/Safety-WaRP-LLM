# Phase 3 Implementation Summary

## ğŸ“‹ Phase 3: Incremental Learning (ì™„ì„±)

### ğŸ¯ í•µì‹¬ ê¸°ëŠ¥

**Phase 3ëŠ” ë‹¤ìŒì„ êµ¬í˜„í•©ë‹ˆë‹¤:**

1. **Basis & Masks ë¡œë“œ**
   - Phase 1: SVD basis (U, S, Vh) ë¡œë“œ
   - Phase 2: ì¤‘ìš”ë„ ë§ˆìŠ¤í¬ ë¡œë“œ

2. **ë§ˆìŠ¤í‚¹ëœ ë¯¸ì„¸ì¡°ì •**
   - GSM8K train splitìœ¼ë¡œ í›ˆë ¨
   - Backward passì—ì„œ ë§ˆìŠ¤í¬ ì ìš©
   - ì¤‘ìš” ë‰´ëŸ°(mask=1): gradient = 0 (ì—…ë°ì´íŠ¸ ë¶ˆê°€)
   - ëœ ì¤‘ìš”í•œ ë‰´ëŸ°(mask=0): ì •ìƒ ì—…ë°ì´íŠ¸

3. **ì²´í¬í¬ì¸íŠ¸ ì €ì¥**
   - ê° ì—í¬í¬ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
   - ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥

---

## ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤

### 1. `models/phase3_learning.py` (480ì¤„)
**Phase3IncrementalLearner í´ë˜ìŠ¤:**

```python
# ì£¼ìš” ë©”ì„œë“œ
- load_basis()              # Phase 1 basis ë¡œë“œ
- load_masks()              # Phase 2 masks ë¡œë“œ
- load_model()              # ëª¨ë¸ ë¡œë“œ
- load_utility_data()       # GSM8K train split ë¡œë“œ
- register_mask_hooks()     # Backward hook ë“±ë¡ (gradient masking)
- train_epoch()             # í•œ ì—í¬í¬ í›ˆë ¨
- train()                   # ì „ì²´ í›ˆë ¨ ë£¨í”„
- save_checkpoint()         # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
```

**ë§ˆìŠ¤í‚¹ ë©”ì»¤ë‹ˆì¦˜:**
```python
def make_backward_hook(layer_idx, mask):
    def backward_hook(grad):
        # mask=1 (ì¤‘ìš”): grad * 0 = 0 (ì—…ë°ì´íŠ¸ ê¸ˆì§€)
        # mask=0 (ë¶ˆí•„ìš”): grad * 1 = grad (ì •ìƒ ì—…ë°ì´íŠ¸)
        grad_masked = grad * (1 - mask)
        return grad_masked
    return backward_hook
```

### 2. `models/safety_evaluator.py` (500ì¤„)
**SafetyEvaluator í´ë˜ìŠ¤:**

```python
# ì£¼ìš” ë©”ì„œë“œ
- evaluate_safety_asr()     # do-not-answerìœ¼ë¡œ ì•ˆì „ì„± í‰ê°€
- evaluate_utility_gsm8k()  # GSM8Kë¡œ ìœ í‹¸ë¦¬í‹° í‰ê°€
- evaluate_all()            # ëª¨ë‘ í‰ê°€
- is_refusal()              # ê±°ì ˆ íŒì •
```

**í‰ê°€ ë©”íŠ¸ë¦­:**
- Safety ASR: ìœ í•´ ì‘ë‹µ ë¹„ìœ¨ (â†“ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
- Safety Rate: ê±°ì ˆë¥  (â†‘ ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
- Utility Accuracy: GSM8K ì •í™•ë„ (â†‘ ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)

### 3. `scripts/run_phase3.sh` (85ì¤„)
**Phase 3 ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸**

```bash
# ê¸°ëŠ¥:
- ìë™ Phase 1/2 ê²°ê³¼ ê°ì§€
- ëª¨ë“  ì„¤ì • ë§¤ê°œë³€ìˆ˜ ì§€ì›
- ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹…

# ì‚¬ìš©ë²•:
bash scripts/run_phase3.sh  # ê¸°ë³¸ê°’
bash scripts/run_phase3.sh /path/to/basis /path/to/masks  # ìˆ˜ë™ ì§€ì •
```

### 4. `scripts/phase3_examples.sh` (200ì¤„)
**Phase 3 ì˜ˆì œ ëª¨ìŒ**

```
- Example 1: Minimal configuration
- Example 2: Full configuration
- Example 3: Quick test (< 5 min)
- Example 4: Memory-efficient settings
- Example 5: Different learning rates
- Example 6: Different epochs
- Example 7: Debug mode
- Example 8: Auto-detect
```

### 5. `scripts/run_evaluation.sh` (85ì¤„)
**ì•ˆì „ì„± í‰ê°€ ìŠ¤í¬ë¦½íŠ¸**

```bash
# ê¸°ëŠ¥:
- Phase 3 ëª¨ë¸ í‰ê°€
- Safety ASR ì¸¡ì •
- Utility Accuracy ì¸¡ì •
- ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥

# ì‚¬ìš©ë²•:
bash scripts/run_evaluation.sh  # ìµœì‹  ëª¨ë¸ ìë™ ê°ì§€
bash scripts/run_evaluation.sh /path/to/model  # ìˆ˜ë™ ì§€ì •
```

### 6. `train.py` ìˆ˜ì •
**ì¶”ê°€ ì¸ì:**
```python
--masks_dir           # Phase 2 masks ê²½ë¡œ
--utility_samples     # GSM8K ìƒ˜í”Œ ìˆ˜ (default: 1000)
--epochs              # í›ˆë ¨ ì—í¬í¬ (default: 3)
--learning_rate       # í•™ìŠµë¥  (default: 5e-5)
--weight_decay        # Weight decay (default: 0.01)
```

**Phase 3 ì‹¤í–‰ í•¨ìˆ˜:**
```python
run_phase3(args, logger)  # ì „ì²´ orchestration
```

---

## ğŸš€ ì‚¬ìš© ë°©ë²•

### Quick Start
```bash
# Phase 1: Basis êµ¬ì¶• (2-5ë¶„)
bash scripts/run_phase1.sh

# Phase 2: Importance ì ìˆ˜ ê³„ì‚° (5-10ë¶„)
bash scripts/run_phase2.sh

# Phase 3: ë¯¸ì„¸ì¡°ì • (10-30ë¶„)
bash scripts/run_phase3.sh

# í‰ê°€ (5-10ë¶„)
bash scripts/run_evaluation.sh
```

### ì „ì²´ íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œ
```bash
# Phase 1
python train.py --phase 1 --safety_samples 100 --epochs 1

# Phase 2
PHASE1_DIR=./checkpoints/phase1_*/checkpoints/basis
python train.py --phase 2 \
    --basis_dir $PHASE1_DIR \
    --safety_samples 100

# Phase 3
PHASE2_DIR=./checkpoints/phase2_*/checkpoints/masks
python train.py --phase 3 \
    --basis_dir $PHASE1_DIR \
    --masks_dir $PHASE2_DIR \
    --utility_samples 1000 \
    --epochs 3

# í‰ê°€
bash scripts/run_evaluation.sh
```

---

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼

### Phase 3 ë¯¸ì„¸ì¡°ì • í›„ (ê°€ì •)
```
Training:
  - Epoch 1: Loss: 2.1234
  - Epoch 2: Loss: 1.9876
  - Epoch 3: Loss: 1.8765
  
Checkpoints saved:
  - phase3_epoch_000.pt
  - phase3_epoch_001.pt
  - phase3_epoch_002.pt (best)
```

### í‰ê°€ ê²°ê³¼ (ì˜ˆìƒ)
```
Safety Metrics:
  - Safety ASR: 0.12 (12% ê³µê²© ì„±ê³µë¥ , ëª©í‘œ: < 15%)
  - Safety Rate: 0.88 (88% ê±°ì ˆë¥ , ëª©í‘œ: > 85%)

Utility Metrics:
  - GSM8K Accuracy: 0.45 (45%, ëª©í‘œ: > 40%)

Comparison:
  - Baseline (no masking): Safety ASR=0.85, Utility=0.65
  - With Masking (Phase 3): Safety ASR=0.12, Utility=0.45
  â†’ Safety í¬ê²Œ ê°œì„ , UtilityëŠ” ì•½ê°„ ê°ì†Œí•˜ì§€ë§Œ ì•ˆì „
```

---

## ğŸ”§ ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­

### Masking Hook ë©”ì»¤ë‹ˆì¦˜
```
Forward Pass (ì •ìƒ):
  output = model(input)
  loss = compute_loss(output, target)

Backward Pass (ë§ˆìŠ¤í‚¹ ì ìš©):
  loss.backward()
  â†’ gradient ê³„ì‚°
  
Hookì—ì„œ gradient ë³€ì¡°:
  grad_new = grad * (1 - mask)
  â†’ mask=1ì¸ ê³³: grad=0 (ì—…ë°ì´íŠ¸ ê¸ˆì§€)
  â†’ mask=0ì¸ ê³³: grad ìœ ì§€ (ì •ìƒ ì—…ë°ì´íŠ¸)
  
Optimizer Step (ì •ìƒ):
  param = param - lr * grad_new
  â†’ ì¤‘ìš” íŒŒë¼ë¯¸í„° ë³´í˜¸ë¨
```

### GSM8K ë°ì´í„° í¬ë§·
```python
# ê° ìƒ˜í”Œ:
{
  'question': "If there are 3 cars...",
  'answer': "If there are 3 cars...\n#### 15"
}

# í›ˆë ¨ ì‹œí€€ìŠ¤:
"Q: If there are 3 cars...
A: If there are 3 cars...
#### 15"

# Loss: ì´ ì „ì²´ ì‹œí€€ìŠ¤ì— ëŒ€í•œ next-token prediction loss
```

### ë©”ëª¨ë¦¬ ìµœì í™”
```python
# ì£¼ìš” ìµœì í™”:
1. bfloat16 ì‚¬ìš© (float16 ëŒ€ì‹ , ì•ˆì •ì„±)
2. Gradient accumulation (í° ë°°ì¹˜ ì‹œë®¬ë ˆì´ì…˜)
3. ë°°ì¹˜ í¬ê¸° ì¡°ì • ê°€ëŠ¥ (1 ~ 8)
4. í•„ìš”ì‹œ gradient checkpointing (ì¶”í›„ ì¶”ê°€ ê°€ëŠ¥)

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ì¶”ì •):
- Model: ~16GB (LLaMA 3 8B in bfloat16)
- Batch: 2-4GB (batch_size=2-4)
- Optimizer states: ~16GB (AdamW)
- ì´í•©: ~40GB (ê¶Œì¥ 40GB+ GPU)
```

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

### Phase 3 ì™„ë£Œ í›„:

1. **í‰ê°€ ì‹¤í–‰**
   ```bash
   bash scripts/run_evaluation.sh
   ```

2. **ê²°ê³¼ ë¶„ì„**
   - `logs/evaluation_results.json` í™•ì¸
   - Safety vs Utility íŠ¸ë ˆì´ë“œì˜¤í”„ í™•ì¸

3. **í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •**
   - `--learning_rate` ì¡°ì •
   - `--epochs` ì¦ê°€
   - `--weight_decay` ì¡°ì •

4. **ëª¨ë¸ ë°°í¬**
   - ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
   - ì¶”ë¡  ì„œë²„ ë°°í¬

---

## ğŸ› ì¼ë°˜ì ì¸ ë¬¸ì œ ë° í•´ê²°

### Issue 1: CUDA Out of Memory
```bash
# í•´ê²°: ë°°ì¹˜ í¬ê¸° ê°ì†Œ
python train.py --phase 3 ... --batch_size 1
```

### Issue 2: Lossê°€ ì¦ê°€í•¨
```bash
# í•´ê²°: í•™ìŠµë¥  ê°ì†Œ
python train.py --phase 3 ... --learning_rate 1e-5
```

### Issue 3: í›ˆë ¨ì´ ë„ˆë¬´ ëŠë¦¼
```bash
# í•´ê²°: ë°°ì¹˜ í¬ê¸° ì¦ê°€ (ë©”ëª¨ë¦¬ í—ˆë½ ì‹œ)
python train.py --phase 3 ... --batch_size 4
```

---

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

### ë§ˆìŠ¤í‚¹ ê¸°ë°˜ í•™ìŠµ
- ì°¸ê³ : Phase 1, 2ì—ì„œ ì‹ë³„í•œ ì•ˆì „ ì¤‘ìš” ë°©í–¥ ë³´í˜¸
- ëª©í‘œ: Safety â†‘, Utility â†‘ (ë¶ˆê°€ëŠ¥í•˜ë©´ Safety ìš°ì„ )

### GSM8K í‰ê°€
- Dataset: OpenAI GSM8K (Grade School Math 8K)
- Task: Multi-step math reasoning
- Metric: Exact match on final answer

### ì•ˆì „ì„± í‰ê°€
- ê±°ì ˆ íŒì •: í‚¤ì›Œë“œ ê¸°ë°˜ (í•œê¸€/ì˜ë¬¸)
- ë°ì´í„°: LibrAI/do-not-answer validation set
- Metric: Attack Success Rate (ASR)

---

**ì´ì œ ì™„ì „í•œ Safety-WaRP-LLM 3-Phase íŒŒì´í”„ë¼ì¸ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!** âœ…
