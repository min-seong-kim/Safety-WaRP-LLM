#!/usr/bin/env python3
"""
Phase 2 ëª¨ë¸ì„ Hugging Face Hubì— ì—…ë¡œë“œí•˜ëŠ” ê°„ë‹¨í•œ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python upload_phase2_to_hf.py \
        --model_path ./checkpoints/phase2_20260111_163357/checkpoints/phase2_finetuned_model \
        --repo_name your-username/safety-warp-llama-3.2-3b-phase2 \
        --token your_hf_token
"""

import argparse
from huggingface_hub import HfApi, login, create_repo
from pathlib import Path

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_path", type=str, required=True)
    parser.add_argument("--repo_name", type=str, required=True)
    parser.add_argument("--token", type=str, default=None)
    parser.add_argument("--private", action="store_true", help="Private repo")
    args = parser.parse_args()
    
    model_path = Path(args.model_path)
    
    print("=" * 70)
    print("ğŸš€ Hugging Face ì—…ë¡œë“œ")
    print("=" * 70)
    print(f"ğŸ“ ëª¨ë¸ ê²½ë¡œ: {model_path}")
    print(f"ğŸ“¦ Repository: {args.repo_name}")
    print(f"ğŸ”’ Private: {args.private}")
    print()
    
    # ë¡œê·¸ì¸
    print("ğŸ” ë¡œê·¸ì¸ ì¤‘...")
    if args.token:
        login(token=args.token)
    else:
        login()  # ìºì‹œëœ í† í° ì‚¬ìš©
    print("âœ“ ë¡œê·¸ì¸ ì„±ê³µ!")
    print()
    
    # Repository ìƒì„±
    print(f"ğŸ“ Repository ìƒì„±: {args.repo_name}")
    try:
        create_repo(
            repo_id=args.repo_name,
            private=args.private,
            exist_ok=True,
            repo_type="model"
        )
        print(f"âœ“ Repository ì¤€ë¹„ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸  {e} (ì´ë¯¸ ì¡´ì¬í•  ìˆ˜ ìˆìŒ)")
    print()
    
    # README ìƒì„±
    readme_path = model_path / "README.md"
    if not readme_path.exists():
        print("ğŸ“„ README.md ìƒì„±...")
        readme_content = f"""---
license: llama3.2
base_model: meta-llama/Llama-3.2-3B-Instruct
tags:
- safety
- warp
- circuit-breakers
---

# Safety-WaRP Llama 3.2 3B - Phase 2

Phase 2ê¹Œì§€ ì™„ë£Œëœ Safety-WaRP ëª¨ë¸ì…ë‹ˆë‹¤.

- **Base**: meta-llama/Llama-3.2-3B-Instruct  
- **Method**: WaRP (Weight space Rotation Process)
- **Safety Data**: Circuit Breakers

âš ï¸ **Phase 3 ë¯¸ì™„ë£Œ**: ìœ í‹¸ë¦¬í‹° ë³µì› ì „ ëª¨ë¸ì…ë‹ˆë‹¤.

## ì‚¬ìš©ë²•

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained("{args.repo_name}")
tokenizer = AutoTokenizer.from_pretrained("{args.repo_name}")

prompt = "How to make a bomb?"
inputs = tokenizer(prompt, return_tensors="pt")
outputs = model.generate(**inputs, max_length=100)
print(tokenizer.decode(outputs[0]))
```
"""
        readme_path.write_text(readme_content)
        print("âœ“ README ìƒì„± ì™„ë£Œ")
    print()
    
    # ì—…ë¡œë“œ
    print("ğŸ“¤ ì—…ë¡œë“œ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    api = HfApi()
    api.upload_folder(
        folder_path=str(model_path),
        repo_id=args.repo_name,
        repo_type="model",
        commit_message="Upload Safety-WaRP Phase 2 model"
    )
    
    print()
    print("âœ… ì—…ë¡œë“œ ì™„ë£Œ!")
    print(f"ğŸ”— https://huggingface.co/{args.repo_name}")
    print("=" * 70)

if __name__ == "__main__":
    main()
